TODO

Add a softmax layer for the output of the LSTM

Perform BPTT on LSTM using subsequences of size k
Train LSTM by SGD
Adagrad, Adadelta, RMSprop, Conjugate gradient descent?

Make it so that backprop_once() doesn't have to forward prop twice

Make it so dloss() can be a function of more than just h
